{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PaulPark2022/Emotions-NLP-Classification-A01709885.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-aAJ1JREFqs",
        "outputId": "0ebe137b-5722-43ec-be03-79f34e183577"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Emotions-NLP-Classification-A01709885'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (11/11), 709.20 KiB | 4.67 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts7voj-R1jL4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Función para leer txt y separar texto/emoción\n",
        "def load_txt(path):\n",
        "    texts, labels = [], []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            text, label = line.strip().split(';')\n",
        "            texts.append(text)\n",
        "            labels.append(label)\n",
        "    return texts, labels\n",
        "\n",
        "# Cargar datasets\n",
        "train_texts, train_labels = load_txt('train.txt')\n",
        "val_texts, val_labels = load_txt('val.txt')\n",
        "test_texts, test_labels = load_txt('test.txt')\n",
        "\n",
        "# Convertir etiquetas a números\n",
        "le = LabelEncoder()\n",
        "train_labels_enc = le.fit_transform(train_labels)\n",
        "val_labels_enc = le.transform(val_labels)\n",
        "test_labels_enc = le.transform(test_labels)\n",
        "\n",
        "# Tokenizar textos\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_seq = tokenizer.texts_to_sequences(train_texts)\n",
        "val_seq = tokenizer.texts_to_sequences(val_texts)\n",
        "test_seq = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding\n",
        "max_len = 50\n",
        "train_pad = pad_sequences(train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "val_pad = pad_sequences(val_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=max_len),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "93HxVw6S_63R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_pad, train_labels_enc,\n",
        "    validation_data=(val_pad, val_labels_enc),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "wlHGp9EtADbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vpotBIOSAHSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar en test\n",
        "loss, acc = model.evaluate(test_pad, test_labels_enc)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Opciones de mejora:\n",
        "# - Ajustar tamaño de LSTM (32, 128)\n",
        "# - Cambiar Dropout (0.3, 0.7)\n",
        "# - Usar Embedding preentrenado (GloVe)\n",
        "# - Probar GRU en vez de LSTM"
      ],
      "metadata": {
        "id": "WkShpKlnAJ1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de predicción\n",
        "def predict_emotion(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
        "    pred = model.predict(pad)\n",
        "    emotion = le.inverse_transform([pred.argmax()])[0]\n",
        "    return emotion\n",
        "\n",
        "# Ejemplos\n",
        "print(predict_emotion(\"I feel so happy today!\"))  # -> joy\n",
        "print(predict_emotion(\"I can't stop crying.\"))    # -> sadness"
      ],
      "metadata": {
        "id": "H4k8vqh-AL0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}