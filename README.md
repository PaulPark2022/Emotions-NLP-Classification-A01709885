# EMOTIONS NLP CLASSIFICATION

**Autor:** Paul Park (A01709885)  
**Fecha:** 7 de noviembre de 2025  

## üß† Descripci√≥n general
Este proyecto implementa un modelo de *deep learning* para la **clasificaci√≥n de emociones en texto**, aplicando una arquitectura de **red LSTM bidireccional** en TensorFlow/Keras.  

El objetivo es que el modelo identifique la emoci√≥n dominante en una oraci√≥n en ingl√©s, entre seis posibles categor√≠as:
**joy, sadness, anger, fear, love, surprise**.

---

## üìÇ Estructura del repositorio
| Archivo | Descripci√≥n |
|----------|--------------|
| `Emotions_Training.ipynb` | Entrena el modelo desde cero. Descarga el dataset, preprocesa, entrena, eval√∫a y guarda el modelo entrenado. |
| `Emotions_Prediction.ipynb` | Carga el modelo ya entrenado y permite hacer predicciones inmediatas sobre nuevos textos. |
| `train.txt`, `val.txt`, `test.txt` | Archivos de datos con frases y sus etiquetas emocionales separadas por punto y coma. |
| `emotion_model.h5` | Modelo LSTM bidireccional entrenado y guardado. |
| `tokenizer.pkl`, `label_encoder.pkl` | Objetos serializados necesarios para el preprocesamiento y decodificaci√≥n. |

---

## üß© Arquitectura de la red
- **Capa de Embedding** (dimensi√≥n 128)
- **LSTM bidireccional** (128 unidades)
- **Dropout** (0.6 y 0.4 para regularizaci√≥n)
- **Capa densa** (64 unidades ReLU)
- **Capa de salida Softmax** (6 clases)
- **Optimizador:** Adam  
- **P√©rdida:** Sparse Categorical Crossentropy  
- **M√©trica:** Accuracy

---

## üöÄ Resultados
- Precisi√≥n en el conjunto de prueba: **‚âà 90 %**
- Buen equilibrio entre *accuracy* y *loss*  
- Las clases m√°s f√°cilmente distinguibles fueron **joy** y **sadness**.  
- Clases con mayor confusi√≥n: **love** y **surprise**, debido a su ambig√ºedad sem√°ntica.

---

## ‚öôÔ∏è Instrucciones de uso

### üß† Entrenamiento (opcional)
Si deseas volver a entrenar el modelo desde cero:
1. Abre `Emotions_Training.ipynb` en Google Colab.  
2. Ejecuta todas las celdas (toma ~15 minutos).  
3. Se generar√°n los archivos:
   - `emotion_model.h5`
   - `tokenizer.pkl`
   - `label_encoder.pkl`

### ‚ö° Predicci√≥n (demostraci√≥n r√°pida)
1. Abre `Emotions_Prediction.ipynb`.  
2. Aseg√∫rate de tener los archivos `.h5` y `.pkl` en la misma carpeta.  
3. Ejecuta todo el notebook.  
4. Prueba con tus propias frases:
   ```python
   predict_emotion("I'm feeling nervous about tomorrow.")

## üßæ Documentaci√≥n t√©cnica

Los experimentos y m√©tricas de desempe√±o (curvas de accuracy/loss y reportes de clasificaci√≥n) se encuentran en el notebook
Emotions_Training.ipynb.
Muestra tanto los resultados visuales como textuales, junto con una comparaci√≥n entre el modelo base y el modelo mejorado.

## üß© Mejoras implementadas

- Incremento de dimensi√≥n en embeddings (64 ‚Üí 128)
- M√°s unidades LSTM (64 ‚Üí 128)
- Nuevas capas de Dropout para regularizaci√≥n
- Uso de EarlyStopping
- Separaci√≥n de entrenamiento y predicci√≥n en Colabs distintos para mayor eficiencia

## üîÆ Futuras mejoras

- Uso de embeddings preentrenados (GloVe, Word2Vec)
- Integraci√≥n de modelos basados en Transformers (BERT)
- Expansi√≥n del dataset con ejemplos multiling√ºes
- Despliegue del modelo en una API o interfaz web interactiva
